{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototypical neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prototypical networks are a type of neural network proposed for the task of few-shot learning i.e. the task of learning to classify examples from classes not seen during training after being given only a few examples of the new classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{prf:observation} Squared Euclidean distance is a regular Bregman divergence\n",
    ":class: dropdown\n",
    "\n",
    "The squared Euclidean distance of two vectors $\\vec{x}, \\vec{y} \\in \\mathbb{R}^N$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "||\\vec{x}-\\vec{y}||^2 &= \\left(\\sqrt{ (x_1-y_1)^2 + (x_2-y_2)^2 + \\dots + (x_N-y_N)^2 }\\right)^2  \\\\\n",
    "&= (x_1-y_1)^2 + (x_2-y_2)^2 + \\dots + (x_N-y_N)^2 \\\\\n",
    "&= (x_1^2-2x_1y_1 + y_1^2) + (x_2^2-2x_2y_2 + y_2^2) + \\dots +  (x_N^2-2x_Ny_N + y_N^2) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Letting $\\varphi(\\vec{y})=\\sum_{i=1}^{N}y_i^2$, which is clearly differentiable and strictly convex as it is the sum of strictly convex differentiable functions, we have \n",
    "\n",
    "$$\n",
    "\\nabla\\varphi(\\vec{y})=[2y_1,...,2y_N].\n",
    "$$ \n",
    "\n",
    "And of course \n",
    "\n",
    "$$\n",
    "(\\vec{x}-\\vec{y})=[x_1-y_1,...,x_N-y_N]\n",
    "$$\n",
    "\n",
    "Plugging all of this into Eq. 3 from the paper we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "d_\\varphi(\\vec{x}, \\vec{y}) &= \\varphi(\\vec{x})-\\varphi(\\vec{y})-(\\vec{x}-\\vec{y})^T\\nabla\\varphi(\\vec{y}) \\\\\n",
    "&= \\sum_{i=1}^{N}x_i^2 - \\sum_{i=1}^{N}y_i^2 - [x_1-y_1,...,x_N-y_N]^T[2y_1,...,2y_N]\\\\\n",
    "&= \\sum_{i=1}^{N}x_i^2 - \\sum_{i=1}^{N}y_i^2 - \\sum_{i=1}^{N} (2x_iy_i - 2y_i^2) \\\\\n",
    "&= \\sum_{i=1}^{N}x_i^2 - \\sum_{i=1}^{N}y_i^2 - \\sum_{i=1}^{N} 2x_iy_i + \\sum_{i=1}^{N} 2y_i^2 \\\\\n",
    "&= \\sum_{i=1}^{N}x_i^2 + \\sum_{i=1}^{N}y_i^2 - \\sum_{i=1}^{N} 2x_iy_i \\\\\n",
    "&= (x_1^2-2x_1y_1 + y_1^2) + (x_2^2-2x_2y_2 + y_2^2) + \\dots +  (x_N^2-2x_Ny_N + y_N^2) \\\\ \n",
    "&= ||\\vec{x}-\\vec{y}||^2 \\quad \\blacksquare\n",
    "\\end{align}\n",
    "\n",
    "$$\n",
    "\n",
    "We have thus proven that the squared Euclidean distance is in fact a regular Bregman divergence.\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch import nn, optim, Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.convolutional_block(input_dim, hidden_dim),\n",
    "            self.convolutional_block(hidden_dim, hidden_dim),\n",
    "            self.convolutional_block(hidden_dim, hidden_dim),\n",
    "            self.convolutional_block(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        output = self.encoder(input)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def convolutional_block(self, in_channels: int, out_channels: int = 64) -> nn.Module:\n",
    "        '''\n",
    "        Returns a block conv-bn-relu-maxpool layer a described in the paper.\n",
    "        '''\n",
    "        return nn.Sequential(\n",
    "            # in the paper 64 out_channels (feature maps) were used with a kernel of size 3x3\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            # in the paper a 2x2 max pooling layer was used\n",
    "            nn.MaxPool2d(2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetworkTrainer:\n",
    "    def __init__(self, learning_rate: float):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def train() -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 4])\n",
      "torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.rand((2, 3, 70, 70))\n",
    "proto_net = PrototypicalNetwork(input_dim=3, hidden_dim=64, output_dim=64)\n",
    "\n",
    "out = proto_net(test_input)\n",
    "\n",
    "print(out[0].shape)\n",
    "\n",
    "print(out[0].view(64, -1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Sun Mar 02 2025\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.12\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "optuna: 4.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
